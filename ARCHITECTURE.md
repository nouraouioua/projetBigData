# üìê Architecture Technique du Projet

## Vue d'Ensemble

Ce document d√©crit l'architecture technique compl√®te du projet d'analyse de logs web.

## Architecture Globale

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         DATA SOURCE                             ‚îÇ
‚îÇ                    NASA Web Server Logs                         ‚îÇ
‚îÇ              (Jul 1995 + Aug 1995 = 3.3M lignes)               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      SPARK CORE LAYER                           ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ   LogParser  ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  DataFrame   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ    Cache     ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  (Regex)     ‚îÇ    ‚îÇ  (Structured)‚îÇ    ‚îÇ              ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ                ‚îÇ                ‚îÇ                  ‚îÇ
        ‚ñº                ‚ñº                ‚ñº                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Spark SQL   ‚îÇ ‚îÇ    MLlib     ‚îÇ ‚îÇ   GraphX     ‚îÇ ‚îÇ  Streaming   ‚îÇ
‚îÇ              ‚îÇ ‚îÇ              ‚îÇ ‚îÇ              ‚îÇ ‚îÇ              ‚îÇ
‚îÇ  Analytics   ‚îÇ ‚îÇ  Clustering  ‚îÇ ‚îÇ IP-URL Graph ‚îÇ ‚îÇ Real-time    ‚îÇ
‚îÇ  KPI         ‚îÇ ‚îÇ  Anomalies   ‚îÇ ‚îÇ Communities  ‚îÇ ‚îÇ Processing   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ                ‚îÇ                ‚îÇ                 ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                       EXPORT LAYER                              ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ Parquet ‚îÇ  ‚îÇ  JSON   ‚îÇ  ‚îÇ    CSV    ‚îÇ  ‚îÇ  Prometheus  ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ            ‚îÇ             ‚îÇ                ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
               ‚îÇ   GRAFANA        ‚îÇ
               ‚îÇ   Dashboard      ‚îÇ
               ‚îÇ   Visualization  ‚îÇ
               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Composants D√©taill√©s

### 1. Couche de Parsing (`src/log_parser.py`)

**Responsabilit√©:** Transformer les logs bruts en DataFrame structur√©

**Technologies:**
- Spark Core (RDD)
- Spark SQL (DataFrame API)
- Regex avanc√©

**Pipeline:**
```
Log brut (texte)
    ‚Üì Regex Pattern Matching
IP, timestamp, method, URL, protocol, status, bytes
    ‚Üì Type Conversion
Integer, Long, Timestamp
    ‚Üì Feature Engineering
hour, day_of_week, is_error, status_category
    ‚Üì
DataFrame structur√© et typ√©
```

**Regex Pattern:**
```regex
^(\S+) (\S+) (\S+) \[([\w:/]+\s[+\-]\d{4})\] "(\S+)\s?(\S+)?\s?(\S+)?" (\d{3}|-) (\d+|-)
```

**Sch√©ma de sortie:**
```python
root
 |-- ip: string
 |-- timestamp: timestamp
 |-- method: string
 |-- url: string
 |-- protocol: string
 |-- status: integer
 |-- bytes: long
 |-- hour: integer
 |-- day_of_week: integer
 |-- date: string
 |-- is_error: integer
 |-- status_category: string
```

### 2. Couche SQL Analytics (`src/sql_analytics.py`)

**Responsabilit√©:** Extraire des KPI et insights via SQL

**Op√©rations principales:**

#### a. Agr√©gations Temporelles
```sql
-- Acc√®s par heure
SELECT date, hour, COUNT(*) as access_count, COUNT(DISTINCT ip) as unique_ips
FROM logs
GROUP BY date, hour
```

#### b. Classements
```sql
-- Top URLs
SELECT url, COUNT(*) as hit_count, COUNT(DISTINCT ip) as unique_visitors
FROM logs
GROUP BY url
ORDER BY hit_count DESC
LIMIT 20
```

#### c. Analyses d'Erreurs
```sql
-- Distribution des erreurs
SELECT status, url, COUNT(*) as error_count
FROM logs
WHERE status >= 400
GROUP BY status, url
```

#### d. Fen√™tres Temporelles
```python
# Window de 10 minutes
window('timestamp', '10 minutes').alias('time_window')
```

**Optimisations:**
- Broadcast joins pour petites tables
- Adaptive Query Execution
- Partitionnement adaptatif
- Cache des DataFrames fr√©quents

### 3. Couche ML (`src/anomaly_detection.py`)

**Responsabilit√©:** D√©tecter les comportements anormaux

#### a. Feature Engineering

**Features par IP:**
```python
features = [
    'request_count',      # Nombre total de requ√™tes
    'unique_urls',        # URLs uniques visit√©es
    'total_bytes',        # Bytes totaux transf√©r√©s
    'error_count',        # Nombre d'erreurs
    'error_rate',         # Taux d'erreur (0-1)
    'requests_per_day',   # Moyenne requ√™tes/jour
    'bytes_per_request',  # Taille moyenne des requ√™tes
    'active_hours'        # Nombre d'heures d'activit√©
]
```

#### b. Pipeline ML

```
Features brutes
    ‚Üì VectorAssembler
Feature vector
    ‚Üì StandardScaler (mean=0, std=1)
Normalized features
    ‚Üì K-Means (k=5)
Cluster assignment
    ‚Üì Distance to centroid
Anomaly score
```

#### c. Algorithmes Utilis√©s

**1. K-Means Clustering**
- Nombre de clusters: 5 (configurable)
- Initialisation: k-means++
- M√©thode de d√©tection: Distance au centro√Øde + taille du cluster
- Anomalies: Points dans les petits clusters + haute distance

**2. Analyse Statistique (Z-score)**
```python
z_score = (value - mean) / std_dev
anomaly = |z_score| > 3.0
```

**Avantages:**
- K-Means: Identifie les groupes de comportements
- Z-score: D√©tecte les outliers extr√™mes
- Compl√©mentaires: Diff√©rents types d'anomalies

### 4. Couche Graphe (`src/graph_analyzer.py`)

**Responsabilit√©:** Analyser les relations IP ‚Üî URL

#### a. Structure du Graphe

**Type:** Graphe biparti (bipartite graph)

```
Vertices:
  - Type IP:   {id: "192.168.1.1", type: "ip"}
  - Type URL:  {id: "/index.html", type: "url"}

Edges:
  - Direction: IP ‚Üí URL
  - Poids: nombre de requ√™tes
  - Attributs: total_bytes, error_count
```

#### b. M√©triques de Graphe

**Out-degree (IPs):**
```python
# Nombre d'URLs visit√©es par une IP
out_degree = graph.outDegrees
```

**In-degree (URLs):**
```python
# Nombre d'IPs ayant visit√© une URL
in_degree = graph.inDegrees
```

**Community Detection:**
```python
# Label Propagation Algorithm
communities = graph.labelPropagation(maxIter=5)
```

#### c. Patterns Suspects

**Indicateurs:**
- IP avec out-degree > 500 ‚Üí Scraper potentiel
- Edge avec error_rate > 50% ‚Üí Attaque potentielle
- IP dans petit cluster isol√© ‚Üí Bot/Scanner

### 5. Couche Streaming (`src/log_streamer.py`)

**Responsabilit√©:** Traitement temps r√©el

#### a. Architecture Streaming

```
File Source (streaming)
    ‚Üì readStream
Raw text DataFrame
    ‚Üì Parser (regex)
Structured stream
    ‚Üì Aggregations (window)
Metrics stream
    ‚Üì writeStream
[Console | Parquet | Memory]
```

#### b. Configuration

**Trigger:** Processing time = 10 seconds
**Watermark:** 10 minutes (late data tolerance)
**Window:** 1 minute, slide 10 seconds

```python
streaming_df.writeStream \
    .trigger(processingTime="10 seconds") \
    .option("checkpointLocation", checkpoint_dir) \
    .start()
```

#### c. Outputs Multiples

1. **Console:** Debugging et monitoring
2. **Parquet:** Persistence pour analyse batch
3. **Memory:** Requ√™tes SQL interactives

### 6. Couche Export (`src/metrics_exporter.py`)

**Responsabilit√©:** Exporter pour visualisation

#### a. Formats Support√©s

**1. Parquet**
- Format optimis√© pour Spark
- Compression columnar
- Schema preservation

**2. JSON**
- Pour Grafana JSON API datasource
- Structure: `[{field1: value1, field2: value2}, ...]`

**3. CSV**
- Pour Grafana CSV plugin
- Header inclus
- UTF-8 encoding

**4. Prometheus**
- M√©triques temps r√©el
- Format exposition Prometheus
- Pull model (port 8000)

#### b. M√©triques Prometheus

```python
# Counter: Cumulative
log_requests_total{status_category="2xx_success"}
log_errors_total{status_code="404"}

# Gauge: Point-in-time
log_unique_ips
log_anomalous_ips

# Histogram: Distribution
log_response_size_bytes
```

## Flux de Donn√©es

### Mode Batch

```
1. Load logs ‚Üí DataFrame
2. Parse ‚Üí Structured DataFrame
3. Cache DataFrame
4. Fork processing:
   ‚îú‚îÄ SQL Analytics ‚Üí KPI DataFrames
   ‚îú‚îÄ ML Clustering ‚Üí Anomalies DataFrame
   ‚îú‚îÄ Graph Analysis ‚Üí Graph + Metrics
   ‚îî‚îÄ All ‚Üí Join results
5. Export all ‚Üí Parquet/JSON/CSV
6. Optional: Start Prometheus server
```

### Mode Streaming

```
1. Setup streaming source (file directory)
2. Create streaming DataFrame
3. Parse in streaming mode
4. Fork streaming queries:
   ‚îú‚îÄ Console query (debug)
   ‚îú‚îÄ Parquet query (persist)
   ‚îî‚îÄ Memory query (interactive)
5. Trigger simulation (chunks every 10s)
6. Monitor queries
7. Shutdown gracefully
```

## Optimisations de Performance

### 1. Caching Strategy

```python
# Cache DataFrames r√©utilis√©s
logs_df.cache()
```

### 2. Partitioning

```python
# Repartition pour balance
df.repartition(200)  # Default shuffle partitions
```

### 3. Broadcast Joins

```python
# Pour petites dimensions
from pyspark.sql.functions import broadcast
large_df.join(broadcast(small_df), "key")
```

### 4. Adaptive Query Execution

```python
spark.conf.set("spark.sql.adaptive.enabled", "true")
spark.conf.set("spark.sql.adaptive.coalescePartitions.enabled", "true")
```

### 5. Predicate Pushdown

```python
# Filtrer t√¥t dans le pipeline
df.filter(col('status') >= 400)  # Avant les aggregations
```

## Scalabilit√©

### Configuration Actuelle
- Driver Memory: 4GB
- Executor Memory: 4GB
- Partitions: 200

### Pour Scaler

**Cluster Spark:**
```python
spark = SparkSession.builder \
    .master("spark://master:7077") \
    .config("spark.executor.instances", "10") \
    .config("spark.executor.cores", "4") \
    .config("spark.executor.memory", "8g") \
    .getOrCreate()
```

**Optimisations pour Big Data:**
- Augmenter partitions: 2-3x le nombre de cores
- Dynamic allocation: auto-scale executors
- Compression: parquet with snappy
- Bucketing: pour joins fr√©quents

## Monitoring et Debugging

### Spark UI
- URL: http://localhost:4040
- Tabs: Jobs, Stages, Storage, Environment, Executors, SQL

### M√©triques Cl√©s
- Job duration
- Shuffle read/write
- GC time
- Spill (memory/disk)

### Logs
```python
spark.sparkContext.setLogLevel("WARN")  # R√©duire verbosit√©
```

## S√©curit√© et Bonnes Pratiques

### 1. Validation des Donn√©es
```python
# Filtrer les lignes invalides
logs_df = logs_df.filter(
    (col('ip') != '') & 
    (col('timestamp').isNotNull())
)
```

### 2. Gestion des Erreurs
```python
try:
    result = process_data(df)
except Exception as e:
    logger.error(f"Processing failed: {e}")
    # Fallback ou retry
```

### 3. Checkpointing (Streaming)
```python
# √âviter la recomputation du DAG
query.option("checkpointLocation", checkpoint_dir)
```

## Technologies et Versions

- **Apache Spark:** 3.5.0
- **Python:** 3.8+
- **PySpark:** 3.5.0
- **GraphFrames:** 0.6+
- **Prometheus Client:** 0.19.0
- **Grafana:** Latest
- **Java:** 8 ou 11

## Limites Connues

1. **GraphFrames:** N√©cessite Scala 2.12 (incompatibilit√© avec 2.13)
2. **Streaming Simulation:** Pas de vraie source temps r√©el
3. **Memory:** N√©cessite au moins 8GB RAM pour dataset complet
4. **Grafana:** Configuration manuelle requise

## Extensions Futures

1. **ML avanc√©:** Isolation Forest, DBSCAN
2. **Deep Learning:** Autoencoders pour anomalies
3. **Geo-IP:** Mapping IP ‚Üí Location
4. **Pattern Mining:** FP-Growth pour associations
5. **Time Series:** ARIMA pour pr√©dictions
6. **Real-time Alerting:** Int√©gration Kafka

---

Cette architecture est modulaire et extensible. Chaque composant peut √™tre remplac√© ou am√©lior√© ind√©pendamment.
